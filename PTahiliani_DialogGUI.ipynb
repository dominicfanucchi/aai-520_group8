{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load DialoGPT-small model and tokenizer\n",
    "model_name = \"microsoft/DialoGPT-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Check if GPU is available and move model to GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Set chat parameters\n",
    "max_length = 1000\n",
    "chat_history_ids = None\n",
    "\n",
    "def chat_with_bot(user_input):\n",
    "    global chat_history_ids\n",
    "    \n",
    "    # Encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Create the attention mask\n",
    "    new_user_attention_mask = torch.ones(new_user_input_ids.shape, dtype=torch.long, device=device)\n",
    "\n",
    "    # Append the new user input tokens to the chat history\n",
    "    if chat_history_ids is not None:\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1)\n",
    "        attention_mask = torch.cat([torch.ones(chat_history_ids.shape, dtype=torch.long, device=device), new_user_attention_mask], dim=-1)\n",
    "    else:\n",
    "        bot_input_ids = new_user_input_ids\n",
    "        attention_mask = new_user_attention_mask\n",
    "\n",
    "    # Generate a response while limiting the total chat history to 1000 tokens\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids, \n",
    "        max_length=max_length,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_k=100,\n",
    "        top_p=0.7,\n",
    "        temperature=0.8,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "    \n",
    "    # Extract the AI's response\n",
    "    ai_response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    \n",
    "    # Optionally, trim conversation history if it gets too long\n",
    "    if chat_history_ids.shape[1] > 1000:\n",
    "        chat_history_ids = chat_history_ids[:, -1000:]\n",
    "    \n",
    "    return ai_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "\n",
    "def chat(*args):\n",
    "    # Get the input from the dialog_entry\n",
    "    user_input = dialog.get()\n",
    "    \n",
    "    # Update the chat_history StringVar\n",
    "    chat_history.set(user_input)\n",
    "    \n",
    "    # Clear the entry field after sending the message\n",
    "    dialog.set(\"\")  # Clear the entry box\n",
    "\n",
    "# Create the main application window\n",
    "app = Tk()\n",
    "app.title(\"AAI520 Dialog Chat\")\n",
    "\n",
    "mainframe = ttk.Frame(app, padding=\"50 3 20 12\")\n",
    "mainframe.grid(column=0, row=0, sticky=(N, W, E, S))\n",
    "\n",
    "# Configure the grid to have 5 columns and 5 rows\n",
    "for i in range(5):\n",
    "    mainframe.columnconfigure(i, weight=1)  # Allow columns to expand\n",
    "    mainframe.rowconfigure(i, weight=1)     # Allow rows to expand\n",
    "\n",
    "# Row 1: Instructions\n",
    "label = ttk.Label(mainframe, text=\"Chat with the AI. Type 'exit', 'quit', or 'end' to finish the conversation.\")\n",
    "label.grid(column=2, row=1, sticky=(W, E))\n",
    "\n",
    "# Row 2: Chat History\n",
    "label = ttk.Label(mainframe, text=\"Chat History:\")\n",
    "label.grid(column=1, row=2, sticky=(W, E))\n",
    "chat_history = StringVar()\n",
    "ttk.Label(mainframe, textvariable=chat_history).grid(column=2, row=2, sticky=(W, E))\n",
    "\n",
    "# Row 3: Input Box\n",
    "label = ttk.Label(mainframe, text=\"Input: \")\n",
    "label.grid(column=1, row=3, sticky=(W, E))\n",
    "\n",
    "dialog = StringVar()\n",
    "dialog_entry = ttk.Entry(mainframe, width=150, textvariable=dialog)\n",
    "dialog_entry.grid(column=2, row=3, sticky=(W, E))\n",
    "\n",
    "# Chat button\n",
    "ttk.Button(mainframe, text=\"Chat\", command=chat).grid(column=2, row=4, sticky=(W, E))\n",
    "\n",
    "# Add padding to all child widgets\n",
    "for child in mainframe.winfo_children(): \n",
    "    child.grid_configure(padx=5, pady=5)\n",
    "\n",
    "# Set focus to the entry field and bind the Enter key to the chat function\n",
    "dialog_entry.focus()\n",
    "app.bind(\"<Return>\", chat)\n",
    "\n",
    "# Run the application\n",
    "app.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
